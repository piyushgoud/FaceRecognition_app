{"cells":[{"cell_type":"code","execution_count":null,"id":"649d42ca","metadata":{"id":"649d42ca"},"outputs":[],"source":["import mtcnn\n","# print version\n","print(mtcnn.__version__)"]},{"cell_type":"code","execution_count":null,"id":"4d15d7ce","metadata":{"id":"4d15d7ce"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statsmodels.api as sm\n","\n","from datetime import datetime\n"]},{"cell_type":"code","execution_count":null,"id":"30bdf526","metadata":{"id":"30bdf526"},"outputs":[],"source":["# Use the mtcnn library to create a face detector and extract faces for use with the FaceNet face detector model in subsequent sections\n","# Define the function extract_face() to load the photo from the loaded filename and return the extracted face. \n","# It assumes the photo contains a face and will return the first face detected\n","from PIL import Image\n","from mtcnn.mtcnn import MTCNN\n"," \n","# Extract a face from a given image\n","\n","def extract_face(filename,  required_size=(160,  160)):\n","    # Load the image as a NumPy array\n","    image = Image.open(filename)\n","    # Convert to RGB format\n","    image = image.convert('RGB')\n","    pixels = np.asarray(image)\n","    # Define detector with default weights\n","    detector = MTCNN()\n","    # Detect face\n","    results = detector.detect_faces(pixels)\n","    # Get the first face bounding box\n","    x1, y1, width, height = results[0]['box']\n","    x1, y1 = abs(x1), abs(y1)\n","    x2, y2 = x1 + width, y1 + height\n","    # Use coordinates to extract faces\n","    face  =  pixels[y1:y2, x1:x2]\n","    # Resize the face to the input size required by FaceNet \n","    image  =  Image.fromarray(face)\n","    image  =  image.resize(required_size)\n","    face_array  =  np.asarray(image)\n","    # Result\n","    return  face_array"]},{"cell_type":"code","execution_count":null,"id":"0eb392b0","metadata":{"id":"0eb392b0"},"outputs":[],"source":["\n","import tensorflow as tf\n","from os import listdir\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"]},{"cell_type":"code","execution_count":null,"id":"e96bd703","metadata":{"scrolled":true,"id":"e96bd703"},"outputs":[],"source":["# We detect the face in each photo for the first 56 photos of Deepika_Padukone in the test dataset.\n","import numpy as np\n","folder = './data_bw/val/Deepika_Padukone/'\n","i = 1\n","# iterate over files\n","for filename in listdir(folder):\n","    # path\n","    if i<=56:\n","        path = folder + filename\n","        # extract face\n","        face = extract_face(path)\n","        print(i, face.shape)\n","        # plot\n","        plt.subplot(8, 7, i)\n","        plt.axis('off')\n","        plt.imshow(face)\n","        i += 1\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"27d4b685","metadata":{"id":"27d4b685"},"outputs":[],"source":["folder = './data_bw/val/Govinda/'\n","i = 1\n","# iterate over files\n","for filename in listdir(folder):\n","    # path\n","    if i<=6:\n","        path = folder + filename\n","        # extract faces\n","        face = extract_face(path)\n","        print(i, face.shape)\n","        # plot\n","        plt.subplot(3, 2, i)\n","        plt.axis('off')\n","        plt.imshow(face)\n","        i += 1\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"a8099bce","metadata":{"scrolled":false,"id":"a8099bce"},"outputs":[],"source":["path = './data_bw/val/Govinda/12.jpg'\n","face = extract_face(path)\n","print(1, face.shape)\n","# plot\n","plt.subplot(1, 3, 1)\n","plt.axis('off')\n","plt.imshow(face)\n","        \n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"c1fcde4a","metadata":{"id":"c1fcde4a"},"outputs":[],"source":["# Each face is correctly detected\n","# Extract the faces for each subdirectory in the train and val folders, and prepare a dataset with names as output labels for each detected face.\n","\n","# load faces\n","def load_faces(directory):\n","    faces  =  list()\n","    for filename in listdir(directory):\n","        # path\n","        path = directory + filename\n","        # extract face\n","        face = extract_face(path)\n","        # save result\n","        faces.append(face)\n","    return  faces"]},{"cell_type":"code","execution_count":null,"id":"694df613","metadata":{"id":"694df613"},"outputs":[],"source":["# Take the input face as X and the label as y\n","def load_dataset(directory):\n","    X, y = list(), list()\n","    for subdir in listdir(directory):\n","        print(subdir)\n","        # path\n","        path = directory + subdir + '/'\n","        from os.path import isdir\n","        if not isdir(path):\n","            continue\n","        # load face\n","        faces = load_faces(path)\n","        # label\n","        labels = [subdir for _ in range(len(faces))]\n","        # save result\n","        X.extend(faces)\n","        y.extend(labels)\n","    return np.asarray(X), np.asarray(y)"]},{"cell_type":"code","execution_count":null,"id":"9a797db3","metadata":{"scrolled":false,"id":"9a797db3"},"outputs":[],"source":["# train\n","trainX, trainy = load_dataset('./data_bw/train/')\n","print(trainX.shape, trainy.shape)\n","\n","# show one picture\n","plt.imshow(trainX[0])\n","\n","trainy[0]\n"]},{"cell_type":"code","execution_count":null,"id":"264b899b","metadata":{"id":"264b899b"},"outputs":[],"source":["# vali\n","testX, testy = load_dataset('./data_bw/val/')\n","print(testX.shape, testy.shape)\n","\n","# Save the result as a numpy npz format file\n","np.savez_compressed('./data_bw.npz', trainX, trainy, testX,  testy)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"MTCNN.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}