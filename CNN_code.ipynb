{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns; sns.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout, MaxPool2D\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Arjun_Rampal', 'Arshad_Warsi', 'Asin', 'Ayushmann_Khurrana', 'Bhumi_Pednekar', 'Bipasha_Basu', 'Bobby_Deol', 'Deepika_Padukone', 'Disha_Patani', 'Emraan_Hashmi', 'Esha_Gupta', 'Farhan_Akhtar', 'Govinda']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "nb_classes = len(class_names)\n",
    "IMAGE_SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input from MTCNN\n",
    "data = np.load('data_bw.npz')\n",
    "trainX,  trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = trainy.shape[0]\n",
    "n_test = testy.shape[0]\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Number of testing examples: {}\".format(n_test))\n",
    "print (\"Each face is of size: {}\".format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "_, train_counts = np.unique(trainy, return_counts=True)\n",
    "_, test_counts = np.unique(testy, return_counts=True)\n",
    "# pd.DataFrame({'train': train_counts,'test': test_counts}, index=class_names).plot.bar(ax=ax)\n",
    "# res = pd.DataFrame({'train': train_counts,'test': test_counts}, index=class_names)\n",
    "# res\n",
    "res = pd.concat([pd.DataFrame(train_counts, index=class_names), pd.DataFrame(test_counts, index=class_names)])\n",
    "res.columns = ['count']\n",
    "res['train_or_test'] = np.array([1]*13 + [0]*13)\n",
    "res['train_or_test'] = np.where(res['train_or_test'] == 1, 'train', 'test')\n",
    "res.index.name = 'celebrity'\n",
    "res.reset_index(drop=False, inplace=True)\n",
    "sns.barplot(x='celebrity', y='count', hue='train_or_test', data=res)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "# plt.savefig(\"./figures/train_test.png\", dpi=800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "trainX = trainX / 255\n",
    "testX = testX / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle to make the validation set random\n",
    "random.seed(4012)\n",
    "\n",
    "trainX, trainy = shuffle(trainX, trainy, random_state=4012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a random image\n",
    "def display_random_image(class_names, images, labels):\n",
    "    index = np.random.randint(images.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('Image #{} : '.format(index) + labels[index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_image(class_names, trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display group of faces\n",
    "def display_examples(class_names, images, labels):\n",
    "    \"\"\"\n",
    "        Display 25 images from the images array with its corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "    for i in range(25):\n",
    "        index = np.random.randint(images.shape[0])\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[index], cmap=plt.cm.binary)\n",
    "        # plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "display_examples(class_names, trainX, trainy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "# perform one-hot encoding on train label\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "print(trainy.shape) #a list without second shape\n",
    "print(trainy.reshape(-1, 1).shape) #change to a 2d array\n",
    "encoder = OneHotEncoder()\n",
    "trainy_hot = encoder.fit_transform(trainy.reshape(-1,1))\n",
    "trainy_hot \n",
    "# trainy_hot is a sparse matrix, convert it to an ndarray\n",
    "trainy_hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one hot encoding on test label\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "encoder = OneHotEncoder()\n",
    "test_labels_hot = encoder.fit_transform(testy.reshape(-1,1))\n",
    "test_labels_hot \n",
    "test_labels_hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CNN fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "tf.random.set_seed(4012)\n",
    "\n",
    "# possible model 1\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (160, 160, 3)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(13, activation = \"softmax\"))\n",
    "model.compile(optimizer='adam' , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(trainX, trainy_hot.toarray(), batch_size=64, epochs=50, validation_split = 0.2)\n",
    "\n",
    "\n",
    "# possible model 2\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "#                       patience=3, \n",
    "#                       verbose=1, \n",
    "#                       factor=0.7, \n",
    "#                       min_lr=0.00000000001)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters = 20, kernel_size = (5,5),padding = 'Same', \n",
    "#                  activation ='relu', input_shape = (160,160,3)))\n",
    "\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(filters = 50, kernel_size = (6,6),padding = 'Same', \n",
    "#                  activation ='relu'))\n",
    "\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(filters = 150, kernel_size = (5,5),padding = 'Same', \n",
    "#                  activation ='relu', input_shape = (160,160,3)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation = \"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(13, activation = \"softmax\"))\n",
    "\n",
    "# model.compile(optimizer = 'adam', loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "# history = model.fit(trainX, trainy_hot.toarray(), batch_size=32, epochs=100, validation_split = 0.2, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on the test set\n",
    "test_loss = model.evaluate(testX, test_labels_hot.toarray())\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(18,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"accuracy\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_accuracy vs val_accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.subplots_adjust()\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define another randomly display function to visualize the result\n",
    "def display_random_image2(class_names, images, labels):\n",
    "    index = np.random.randint(images.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.title('Image #{} : '.format(index) + labels[index])\n",
    "    plt.show()\n",
    "\n",
    "# convert the prediction result (in the format of 2d array) to the name of the celebrity (string)\n",
    "predictions = np.round(model.predict(testX)).astype(int)    # Vector of probabilities\n",
    "pred_labels = np.squeeze(predictions) \n",
    "pred = np.array([class_names[i.argmax()] for i in pred_labels])\n",
    "display_random_image2(class_names, testX, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(model.predict(trainX)).astype(int)    # Vector of probabilities\n",
    "train_labels = np.squeeze(predictions) \n",
    "train = np.array([class_names[i.argmax()] for i in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly plot some mislabeled images\n",
    "def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n",
    "    BOO = (test_labels == pred_labels)\n",
    "    mislabeled_indices = np.where(BOO == 0)\n",
    "    mislabeled_images = test_images[mislabeled_indices]\n",
    "    mislabeled_labels = pred_labels[mislabeled_indices]\n",
    "\n",
    "    title = \"Some examples of mislabeled images by the classifier:\"\n",
    "    display_examples(class_names,  mislabeled_images, mislabeled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_mislabeled_images(class_names, trainX, trainy, train)\n",
    "print_mislabeled_images(class_names, testX, testy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM = confusion_matrix(testy, pred)\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testy, pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(trainy, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "# data = confusion_matrix(trainy, train)\n",
    "data = confusion_matrix(testy, pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(testy), index = np.unique(testy))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (12, 10))\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='d', annot_kws={\"size\": 19}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
